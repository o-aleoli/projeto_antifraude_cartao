{"cells":[{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"96816ed7-b08a-4ca3-abb9-f99880c3535d","showTitle":false,"title":""}},"source":["## Overview\n","\n","This notebook will show you how to create and query a table or DataFrame that you uploaded to DBFS. [DBFS](https://docs.databricks.com/user-guide/dbfs-databricks-file-system.html) is a Databricks File System that allows you to store data for querying inside of Databricks. This notebook assumes that you have a file already inside of DBFS that you would like to read from.\n","\n","This notebook is written in **Python** so the default cell type is Python. However, you can use different languages by using the `%LANGUAGE` syntax. Python, Scala, SQL, and R are all supported."]},{"cell_type":"code","execution_count":1,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"6482be4c-f067-47c9-b0ac-35c938b94601","showTitle":false,"title":""}},"outputs":[{"name":"stderr","output_type":"stream","text":["22/04/01 10:49:40 WARN Utils: Your hostname, freetoaster resolves to a loopback address: 127.0.1.1; using 192.168.1.98 instead (on interface wlo1)\n","22/04/01 10:49:40 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n","WARNING: An illegal reflective access operation has occurred\n","WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/etc/spark-3.2.0-bin-hadoop3.2/jars/spark-unsafe_2.12-3.2.0.jar) to constructor java.nio.DirectByteBuffer(long,int)\n","WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n","WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n","WARNING: All illegal access operations will be denied in a future release\n","Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n","Setting default log level to \"WARN\".\n","To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n","22/04/01 10:49:42 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n","                                                                                \r"]},{"data":{"text/plain":["DataFrame[Time: double, V1: double, V2: double, V3: double, V4: double, V5: double, V6: double, V7: double, V8: double, V9: double, V10: double, V11: double, V12: double, V13: double, V14: double, V15: double, V16: double, V17: double, V18: double, V19: double, V20: double, V21: double, V22: double, V23: double, V24: double, V25: double, V26: double, V27: double, V28: double, Amount: double, Class: int]"]},"metadata":{},"output_type":"display_data"}],"source":["from pyspark.sql import SparkSession\n","\n","spark = SparkSession.builder.getOrCreate()\n","\n","# File location and type\n","file_location = \"creditcard.csv\"\n","file_type = \"csv\"\n","\n","# CSV options\n","infer_schema = \"true\"\n","first_row_is_header = \"true\"\n","delimiter = \",\"\n","\n","# The applied options are for CSV files. For other file types, these will be ignored.\n","df = spark.read.format(file_type) \\\n","  .option(\"inferSchema\", infer_schema) \\\n","  .option(\"header\", first_row_is_header) \\\n","  .option(\"sep\", delimiter) \\\n","  .load(file_location)\n","\n","display(df)"]},{"cell_type":"code","execution_count":2,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"db9631f6-bb4a-42ca-8a3c-0d48af932331","showTitle":false,"title":""}},"outputs":[{"name":"stderr","output_type":"stream","text":["22/04/01 10:50:34 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n","22/04/01 10:50:36 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n","Scaling row group sizes to 95.00% for 8 writers\n","                                                                                \r"]}],"source":["# With this registered as a temp view, it will only be available to this particular notebook. If you'd like other users to be able to query this table, you can also create a table from the DataFrame.\n","# Once saved, this table will persist across cluster restarts as well as allow various users across different notebooks to query this data.\n","# To do so, choose your table name and uncomment the bottom line.\n","\n","permanent_table_name = \"cc_db\"\n","\n","df.write.format(\"parquet\").saveAsTable(permanent_table_name)"]}],"metadata":{"application/vnd.databricks.v1+notebook":{"dashboards":[],"language":"python","notebookMetadata":{"pythonIndentUnit":4},"notebookName":"ELT","notebookOrigID":968805355530920,"widgets":{}},"interpreter":{"hash":"31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"},"kernelspec":{"display_name":"Python 3.9.7 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":0}
